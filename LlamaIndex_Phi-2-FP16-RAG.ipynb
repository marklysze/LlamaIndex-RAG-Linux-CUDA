{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phi-2 (FP16)\n",
    "#### NOTE: YOU WILL NEED LLAMA-CPP-PYTHON VERSION v0.2.24 OR HIGHER\n",
    "\n",
    "This notebook demonstrates the use of LlamaIndex for Retrieval Augmented Generation in Linux and with Nvidia's CUDA.\n",
    "\n",
    "See the [README.md](README.md) file for help on how to run this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare Llama Index for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the Word document(s)\n",
    "\n",
    "Note: A fictitious story about Thundertooth a dinosaur who has travelled to the future. Thanks ChatGPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./Data/\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "llama_model_loader: loaded meta data with 18 key-value pairs and 325 tensors from ./Models/phi-2-ggml-model-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight f16      [  2560, 51200,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:             blk.0.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:           blk.0.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:            blk.0.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:           blk.0.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:         blk.0.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:                blk.0.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:            blk.0.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:             blk.1.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:           blk.1.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:           blk.1.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:                blk.1.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.1.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.1.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:            blk.10.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:          blk.10.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:             blk.10.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:           blk.10.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:          blk.10.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:        blk.10.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:               blk.10.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:             blk.10.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:             blk.10.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.10.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:            blk.11.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:          blk.11.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:           blk.11.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:          blk.11.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:        blk.11.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:               blk.11.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:             blk.11.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:             blk.11.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:           blk.11.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.12.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:          blk.12.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:             blk.12.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.12.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:          blk.12.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:        blk.12.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:               blk.12.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:             blk.12.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.12.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.12.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:            blk.13.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:          blk.13.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:           blk.13.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.13.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:        blk.13.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:               blk.13.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.13.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:             blk.13.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:           blk.13.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.14.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:          blk.14.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:           blk.14.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:          blk.14.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:        blk.14.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:               blk.14.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:             blk.14.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.14.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:           blk.14.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:            blk.15.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:          blk.15.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:             blk.15.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.15.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:          blk.15.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:        blk.15.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:               blk.15.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.15.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:             blk.15.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.15.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.16.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.16.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:             blk.16.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.16.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:          blk.16.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:        blk.16.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:               blk.16.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:             blk.16.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.16.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:           blk.16.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:            blk.17.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:          blk.17.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.17.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:           blk.17.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:          blk.17.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:        blk.17.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:               blk.17.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.17.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.17.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:           blk.17.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:            blk.18.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:          blk.18.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.18.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.18.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:          blk.18.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.18.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:               blk.18.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.18.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.18.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:           blk.18.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.19.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:          blk.19.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:             blk.19.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:           blk.19.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:          blk.19.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:        blk.19.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:               blk.19.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.19.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.19.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.19.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.2.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.2.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.2.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.2.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:           blk.2.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.2.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:                blk.2.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.2.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:              blk.2.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.2.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.20.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:          blk.20.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:             blk.20.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:           blk.20.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:          blk.20.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:        blk.20.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:               blk.20.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.20.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.20.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.20.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:            blk.21.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:          blk.21.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.21.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.21.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.21.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:        blk.21.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:               blk.21.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.21.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:             blk.21.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:           blk.21.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:            blk.22.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.22.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.22.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.22.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:          blk.22.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:        blk.22.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:               blk.22.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:             blk.22.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.22.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.22.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:            blk.23.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:          blk.23.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.23.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.23.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:          blk.23.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.23.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:               blk.23.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.23.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:             blk.23.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:           blk.23.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:            blk.24.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.24.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.24.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.24.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:          blk.24.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:        blk.24.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:               blk.24.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:             blk.24.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.24.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.24.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:            blk.25.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:          blk.25.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.25.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:           blk.25.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:          blk.25.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:        blk.25.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:               blk.25.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.25.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.25.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.25.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.26.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:          blk.26.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.26.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.26.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:          blk.26.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.26.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:               blk.26.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.26.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.26.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.26.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.27.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:          blk.27.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:             blk.27.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:           blk.27.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:          blk.27.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:        blk.27.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:               blk.27.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.27.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.27.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.27.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:            blk.28.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:          blk.28.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.28.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.28.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.28.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:        blk.28.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:               blk.28.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.28.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.28.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.28.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:            blk.29.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:          blk.29.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.29.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:           blk.29.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:          blk.29.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:        blk.29.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:               blk.29.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.29.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.29.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.29.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.3.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.3.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:              blk.3.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:            blk.3.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:           blk.3.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:         blk.3.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:                blk.3.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:              blk.3.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:              blk.3.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:            blk.3.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:            blk.30.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.30.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.4.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:           blk.4.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:              blk.4.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:            blk.4.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.4.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:         blk.4.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:                blk.4.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:              blk.4.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:              blk.4.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:            blk.4.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.5.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.5.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:              blk.5.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:            blk.5.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.5.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:         blk.5.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:                blk.5.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:              blk.5.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:              blk.5.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:            blk.5.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.6.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.6.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:              blk.6.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:            blk.6.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.6.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:         blk.6.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:                blk.6.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:              blk.6.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:              blk.6.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:            blk.6.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.7.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.7.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:              blk.7.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:            blk.7.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.7.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:         blk.7.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:                blk.7.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:              blk.7.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:              blk.7.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:            blk.7.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:             blk.8.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.8.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:              blk.8.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:            blk.8.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:           blk.8.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:         blk.8.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:                blk.8.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:              blk.8.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:              blk.8.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:            blk.8.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.9.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.9.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:              blk.9.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:            blk.9.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:           blk.9.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:         blk.9.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:                blk.9.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:              blk.9.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:              blk.9.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:            blk.9.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:                      output.bias f32      [ 51200,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:                    output.weight f16      [  2560, 51200,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:                 output_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:               output_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.30.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:           blk.30.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:          blk.30.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:        blk.30.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:               blk.30.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:             blk.30.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.30.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:           blk.30.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:            blk.31.attn_norm.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:          blk.31.attn_norm.weight f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:             blk.31.attn_qkv.bias f32      [  7680,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.31.attn_qkv.weight f16      [  2560,  7680,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:          blk.31.attn_output.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:        blk.31.attn_output.weight f16      [  2560,  2560,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:               blk.31.ffn_up.bias f32      [ 10240,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.31.ffn_up.weight f16      [  2560, 10240,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:             blk.31.ffn_down.bias f32      [  2560,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:           blk.31.ffn_down.weight f16      [ 10240,  2560,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  13:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type  f16:  130 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 910/51200 vs 944/51200 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 51200\n",
      "llm_load_print_meta: n_merges         = 50000\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 2560\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 32\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 10240\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = F16\n",
      "llm_load_print_meta: model params     = 2.78 B\n",
      "llm_load_print_meta: model size       = 5.18 GiB (16.01 BPW) \n",
      "llm_load_print_meta: general.name     = Phi2\n",
      "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =  250.12 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors: VRAM used: 5053.65 MiB\n",
      ".............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  =  640.00 MiB, K (f16):  320.00 MiB, V (f16):  320.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 774/774\n",
      "llama_new_context_with_model: compute buffer total size = 165.19 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 162.00 MiB\n",
      "llama_new_context_with_model: total VRAM used: 5215.66 MiB (model: 5053.65 MiB, context: 162.00 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\n",
    "llm = LlamaCPP(\n",
    "    model_url=None, # We'll load locally.\n",
    "    model_path='./Models/phi-2-ggml-model-f16.gguf', # FP16 version of Phi-2\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=1024,\n",
    "    context_window=2048, # Phi-2 2K context window - this could be a limitation for RAG as it has to put the content into this context window\n",
    "    generate_kwargs={},\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 33}, # 33 layers were all that were required and this fit within the RTX 3090's 24GB\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Checkpoint\n",
    "\n",
    "Are you running on GPU? The above output should include near the top something like:\n",
    "> ggml_init_cublas: found 1 CUDA devices:\n",
    "\n",
    "And in the full text near the bottom should be:\n",
    "> llm_load_tensors: using CUDA for GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Embeddings\n",
    "\n",
    "Convert your source document text into embeddings.\n",
    "\n",
    "The embedding model is from huggingface, this one performs well.\n",
    "\n",
    "> https://huggingface.co/thenlper/gte-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: thenlper/gte-large\n",
      "Load pretrained SentenceTransformer: thenlper/gte-large\n",
      "INFO:sentence_transformers.SentenceTransformer:Did not find folder thenlper/gte-large\n",
      "Did not find folder thenlper/gte-large\n",
      "INFO:sentence_transformers.SentenceTransformer:Search model on server: http://sbert.net/models/thenlper/gte-large.zip\n",
      "Search model on server: http://sbert.net/models/thenlper/gte-large.zip\n",
      "INFO:sentence_transformers.SentenceTransformer:Load SentenceTransformer from folder: /home/mark/.cache/torch/sentence_transformers/sbert.net_models_thenlper_gte-large\n",
      "Load SentenceTransformer from folder: /home/mark/.cache/torch/sentence_transformers/sbert.net_models_thenlper_gte-large\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\", cache_folder=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Prompt Template\n",
    "\n",
    "Prompt template for Phi-2 is below. As there's only a prompt we will combine the system message and prompt into the prompt.\n",
    "\n",
    "Instruct: {prompt}<br>\n",
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a prompt specific to the model\n",
    "def modelspecific_prompt(promptmessage):\n",
    "    # As per https://huggingface.co/TheBloke/phi-2-GGUF\n",
    "    return f\"Instruct: {promptmessage}\\nOutput:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Service Context\n",
    "\n",
    "For chunking the document into tokens using the embedding model and our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=256, # Number of tokens in each chunk\n",
    "    # chunk_overlap=1,    # Doesn't allow zero, set to lowest value\n",
    "    # context_window=2048, # This should be automatically set with the model metadata but we'll force it to ensure wit is\n",
    "    # num_output=512, # Maximum output from the LLM, let's put this at 512 to ensure LlamaIndex saves that \"space\" for the output\n",
    "    llm=llm,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Index documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656c0b401dca44e3bb540a5f8db8dd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9213566fde4d45f2b9dd30a758c552f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93bf290d4b944268980d183d595ac26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Query Engine\n",
    "\n",
    "Create a query engine, specifying how many citations we want to get back from the searched text (in this case 3).\n",
    "\n",
    "The DB_DOC_ID_KEY is used to get back the filename of the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import CitationQueryEngine\n",
    "query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    similarity_top_k=3,\n",
    "    # here we can control how granular citation sources are, the default is 512\n",
    "    # citation_chunk_size=256 #256,\n",
    ")\n",
    "\n",
    "# For citations we get the document info\n",
    "DB_DOC_ID_KEY = \"db_document_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_context.node_parser:\n",
      "Chunk Overlap: 200\n",
      "Chunk Size: 256\n",
      "Paragraph Separator: \\n\\n\\n\n",
      "Secondary Chunking RegEx: [^,.;。？！]+[,.;。？！]?\n",
      "Include Metadata: True\n",
      "\n",
      "service_context.prompt_helper:\n",
      "Context Window: 2048\n",
      "Chunk Overlap Ratio: 0.1\n",
      "Chunk Size Limit: None\n",
      "Chunk Separator: '   '\n",
      "Num Output: ' 1024 '\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the chunking and prompting parameters from our service_context\n",
    "\n",
    "print(\"service_context.node_parser:\")\n",
    "print(\"Chunk Overlap:\",service_context.node_parser.chunk_overlap)\n",
    "print(\"Chunk Size:\",service_context.node_parser.chunk_size)\n",
    "print(\"Paragraph Separator:\",service_context.node_parser.paragraph_separator.replace(\"\\n\",\"\\\\n\"))\n",
    "print(\"Secondary Chunking RegEx:\",service_context.node_parser.secondary_chunking_regex)\n",
    "print(\"Include Metadata:\",service_context.node_parser.include_metadata)\n",
    "\n",
    "print(\"\\nservice_context.prompt_helper:\")\n",
    "print(\"Context Window:\", service_context.prompt_helper.context_window) # The maximum context size that will get sent to the LLM.\n",
    "print(\"Chunk Overlap Ratio:\", service_context.prompt_helper.chunk_overlap_ratio) # The percentage token amount that each chunk should overlap.\n",
    "print(\"Chunk Size Limit:\", service_context.prompt_helper.chunk_size_limit) # The maximum size of a chunk.\n",
    "print(\"Chunk Separator: '\", service_context.prompt_helper.separator, \"'\") # The separator when chunking tokens.\n",
    "print(\"Num Output: '\", service_context.prompt_helper.num_output, \"'\") # The number of tokens that should be left to generate in the prompt (default is 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Prompt and Response function\n",
    "\n",
    "Pass in a question, get a response back.\n",
    "\n",
    "IMPORTANT: The prompt is set here, adjust it to match what you want the LLM to act like and do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunQuestion(questionText):\n",
    "    # Excluding the system prompt as the model is including it (even a short version of it) is causing lack of responses in some cases and it is not consistently answering.\n",
    "    prompt = \"\" # \"You are a story teller who likes to elaborate and answers questions in a positive, helpful and interesting way, so please answer the following question - \"\n",
    "    \n",
    "    prompt = prompt + questionText\n",
    "\n",
    "    queryQuestion = modelspecific_prompt(prompt)\n",
    "\n",
    "    response = query_engine.query(queryQuestion)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Questions to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestQuestions = [\n",
    "    \"Summarise this story for me\",\n",
    "    \"Who was the main protagonist?\",\n",
    "    \"Did they have any children? If so, what were their names?\",\n",
    "    \"Did anything eventful happen?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Run Questions through model (this can take a while) and see citations\n",
    "\n",
    "Runs each test question, saves it to a dictionary for output in the last step.\n",
    "\n",
    "Note: Citations are the source documents used and the text the response is based on. This is important for RAG so you can reference these documents for the user, and to ensure it's utilising the right documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/4: Summarise this story for me\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08760e669a694e79bd6db705678fbc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1 of 3: |Thundertooth Part 3.docx| Source 1:\n",
      "Thundertooth, ever the protector of his newfound home, wasted no time. With a determined gleam in his eyes, he gathered his family and hurried to the city's command center, where Mayor Grace and the leading scientists were coordinating the evacuation efforts.\n",
      "\n",
      "\n",
      "\n",
      "The mayor, recognizing Thundertooth's intelligence and resourcefulness, approached him. \"Thundertooth, we need a plan to divert or neutralize the meteor. Our technology can only do so much, but with your unique abilities, perhaps we can find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "Source 2 of 3: |Thundertooth Part 3.docx| Source 2:\n",
      "The mayor, recognizing Thundertooth's intelligence and resourcefulness, approached him. \"Thundertooth, we need a plan to divert or neutralize the meteor. Our technology can only do so much, but with your unique abilities, perhaps we can find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "\n",
      "\n",
      "3. **Sapphire**: Harnessing her calming and healing powers, Sapphire would assist in calming the panicked masses, ensuring an orderly and efficient evacuation.\n",
      "\n",
      "\n",
      "\n",
      "4. **Ignis**: Drawing upon his fiery talents, Ignis would create controlled bursts of heat, attempting to alter the meteor's trajectory and reduce its destructive force.\n",
      "\n",
      "Source 3 of 3: |Thundertooth Part 1.docx| Source 3:\n",
      "\"Hello there, majestic creature. What brings you to our time?\" Mayor Grace inquired, her voice calm and reassuring.\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth, though initially startled, found comfort in the mayor's soothing tone. In broken sentences, he explained his journey through time, the strange portal, and his hunger dilemma. Mayor Grace listened intently, her eyes widening with amazement at the tale of the prehistoric dinosaur navigating the future.\n",
      "\n",
      "\n",
      "\n",
      "Realizing the dinosaur's predicament, Mayor Grace extended an invitation. \"You are welcome in our city, Thundertooth. We can find a way to provide for you without causing harm to anyone. Let us work together to find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Grateful for the mayor's hospitality, Thundertooth followed her through the city. Together, they explored the futuristic marketplaces and innovative food labs, eventually discovering a sustainable solution that satisfied the dinosaur's hunger without compromising the well-being of the city's inhabitants.\n",
      "\n",
      "\n",
      "\n",
      "As the news of Thundertooth's arrival spread, the city embraced the talking dinosaur as a symbol of unity between the past and the future. Thundertooth found a new home in the city's park, where holographic flowers bloomed, and the citizens marveled at the beauty of coexistence across time. And so, in this extraordinary city of flying cars and advanced technology, Thundertooth became a beloved figure, a living bridge between eras, teaching the people that understanding and cooperation could overcome even the greatest challenges.\n",
      "\n",
      "\n",
      "2/4: Who was the main protagonist?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1340.87 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2350.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3941.40 ms /  1150 tokens (    3.43 ms per token,   291.77 tokens per second)\n",
      "llama_print_timings:        eval time =      81.40 ms /     1 runs   (   81.40 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    4036.72 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e429fad476774f1aa073de9bab30f222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1 of 3: |Thundertooth Part 3.docx| Source 1:\n",
      "Thundertooth, ever the protector of his newfound home, wasted no time. With a determined gleam in his eyes, he gathered his family and hurried to the city's command center, where Mayor Grace and the leading scientists were coordinating the evacuation efforts.\n",
      "\n",
      "\n",
      "\n",
      "The mayor, recognizing Thundertooth's intelligence and resourcefulness, approached him. \"Thundertooth, we need a plan to divert or neutralize the meteor. Our technology can only do so much, but with your unique abilities, perhaps we can find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "Source 2 of 3: |Thundertooth Part 3.docx| Source 2:\n",
      "The mayor, recognizing Thundertooth's intelligence and resourcefulness, approached him. \"Thundertooth, we need a plan to divert or neutralize the meteor. Our technology can only do so much, but with your unique abilities, perhaps we can find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "\n",
      "\n",
      "3. **Sapphire**: Harnessing her calming and healing powers, Sapphire would assist in calming the panicked masses, ensuring an orderly and efficient evacuation.\n",
      "\n",
      "\n",
      "\n",
      "4. **Ignis**: Drawing upon his fiery talents, Ignis would create controlled bursts of heat, attempting to alter the meteor's trajectory and reduce its destructive force.\n",
      "\n",
      "Source 3 of 3: |Thundertooth Part 3.docx| Source 3:\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "\n",
      "\n",
      "3. **Sapphire**: Harnessing her calming and healing powers, Sapphire would assist in calming the panicked masses, ensuring an orderly and efficient evacuation.\n",
      "\n",
      "\n",
      "\n",
      "4. **Ignis**: Drawing upon his fiery talents, Ignis would create controlled bursts of heat, attempting to alter the meteor's trajectory and reduce its destructive force.\n",
      "\n",
      "\n",
      "\n",
      "As the citizens evacuated to designated shelters, the Thundertooth family sprang into action. Lumina worked tirelessly to strengthen the city's energy systems, Echo echoed evacuation orders through the city's speakers, Sapphire offered comfort to those in distress, and Ignis unleashed controlled bursts of flames towards the approaching meteor.\n",
      "\n",
      "\n",
      "3/4: Did they have any children? If so, what were their names?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1340.87 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    10 runs   (    0.43 ms per token,  2340.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.26 ms /   295 tokens (    4.31 ms per token,   231.87 tokens per second)\n",
      "llama_print_timings:        eval time =     694.58 ms /     9 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2000.60 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fb6c699dd14315b05ff9aa417c61bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1 of 3: |Thundertooth Part 2.docx| Source 1:\n",
      "As the years passed, Thundertooth's life took a heartwarming turn. He met a kind and intelligent dinosaur named Seraphina, and together they started a family. Thundertooth and Seraphina were blessed with four children, each with unique characteristics that mirrored the diversity of their modern world.\n",
      "\n",
      "\n",
      "\n",
      "Lumina: The eldest of Thundertooth's children, Lumina inherited her mother's intelligence and her father's sense of wonder. With sparkling scales that emitted a soft glow, Lumina had the ability to generate light at will. She became fascinated with technology, often spending hours tinkering with gadgets and inventing new ways to enhance the widgets produced in the family's factory.\n",
      "\n",
      "\n",
      "\n",
      "Echo: The second-born, Echo, had a gift for mimicry. He could perfectly replicate any sound or voice he heard, providing entertainment to the entire city. His playful nature and ability to bring joy to those around him made him a favorite among the neighborhood children.\n",
      "\n",
      "Source 2 of 3: |Thundertooth Part 2.docx| Source 2:\n",
      "As the years passed, Thundertooth's life took a heartwarming turn. He met a kind and intelligent dinosaur named Seraphina, and together they started a family. Thundertooth and Seraphina were blessed with four children, each with unique characteristics that mirrored the diversity of their modern world.\n",
      "\n",
      "\n",
      "\n",
      "Lumina: The eldest of Thundertooth's children, Lumina inherited her mother's intelligence and her father's sense of wonder. With sparkling scales that emitted a soft glow, Lumina had the ability to generate light at will. She became fascinated with technology, often spending hours tinkering with gadgets and inventing new ways to enhance the widgets produced in the family's factory.\n",
      "\n",
      "\n",
      "\n",
      "Echo: The second-born, Echo, had a gift for mimicry. He could perfectly replicate any sound or voice he heard, providing entertainment to the entire city. His playful nature and ability to bring joy to those around him made him a favorite among the neighborhood children.\n",
      "\n",
      "\n",
      "\n",
      "Sapphire: Sapphire, the third sibling, had scales that shimmered like precious gems. She possessed a unique talent for calming and healing, a trait she inherited from both her parents. Whenever someone in the city felt stressed or unwell, Sapphire would extend her gentle touch, bringing comfort and tranquility.\n",
      "\n",
      "Source 3 of 3: |Thundertooth Part 2.docx| Source 3:\n",
      "Thundertooth's toy factory became a sensation, and its creations were highly sought after. The widgets incorporated cutting-edge holographic displays, levitation technology, and even the ability to change shapes and colors with a mere thought. Children across the city rejoiced as they played with these incredible toys that seemed to bring their wildest fantasies to life.\n",
      "\n",
      "\n",
      "\n",
      "As the years passed, Thundertooth's life took a heartwarming turn. He met a kind and intelligent dinosaur named Seraphina, and together they started a family. Thundertooth and Seraphina were blessed with four children, each with unique characteristics that mirrored the diversity of their modern world.\n",
      "\n",
      "\n",
      "\n",
      "Lumina: The eldest of Thundertooth's children, Lumina inherited her mother's intelligence and her father's sense of wonder. With sparkling scales that emitted a soft glow, Lumina had the ability to generate light at will. She became fascinated with technology, often spending hours tinkering with gadgets and inventing new ways to enhance the widgets produced in the family's factory.\n",
      "\n",
      "\n",
      "4/4: Did anything eventful happen?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1340.87 ms\n",
      "llama_print_timings:      sample time =     305.11 ms /  1009 runs   (    0.30 ms per token,  3307.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2701.05 ms /   761 tokens (    3.55 ms per token,   281.74 tokens per second)\n",
      "llama_print_timings:        eval time =   94349.63 ms /  1008 runs   (   93.60 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =  100767.20 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b018bc9270e4bd8b86924d09bb384cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1 of 3: |Thundertooth Part 3.docx| Source 1:\n",
      "Thundertooth stood at the forefront, using his mighty roar to coordinate and inspire the efforts of the city's inhabitants. The ground trembled as the meteor drew closer, but the Thundertooth family's coordinated efforts began to take effect. Lumina's force field shimmered to life, deflecting the meteor's deadly path. Echo's amplified warnings reached every corner of the city, ensuring that no one was left behind.\n",
      "\n",
      "\n",
      "\n",
      "As Ignis's controlled bursts of flames interacted with the meteor, it began to change course. The combined efforts of the Thundertooth family, guided by their unique talents, diverted the catastrophic collision. The meteor, once destined for destruction, now harmlessly sailed past the Earth, leaving the city and its inhabitants unscathed.\n",
      "\n",
      "\n",
      "\n",
      "The citizens, emerging from their shelters, erupted into cheers of gratitude. Mayor Grace approached Thundertooth, expressing her heartfelt thanks for the family's heroic efforts. The Thundertooth family, tired but triumphant, basked in the relief of having saved their beloved city from imminent disaster.\n",
      "\n",
      "Source 2 of 3: |Thundertooth Part 3.docx| Source 2:\n",
      "4. **Ignis**: Drawing upon his fiery talents, Ignis would create controlled bursts of heat, attempting to alter the meteor's trajectory and reduce its destructive force.\n",
      "\n",
      "\n",
      "\n",
      "As the citizens evacuated to designated shelters, the Thundertooth family sprang into action. Lumina worked tirelessly to strengthen the city's energy systems, Echo echoed evacuation orders through the city's speakers, Sapphire offered comfort to those in distress, and Ignis unleashed controlled bursts of flames towards the approaching meteor.\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth stood at the forefront, using his mighty roar to coordinate and inspire the efforts of the city's inhabitants. The ground trembled as the meteor drew closer, but the Thundertooth family's coordinated efforts began to take effect. Lumina's force field shimmered to life, deflecting the meteor's deadly path. Echo's amplified warnings reached every corner of the city, ensuring that no one was left behind.\n",
      "\n",
      "\n",
      "\n",
      "As Ignis's controlled bursts of flames interacted with the meteor, it began to change course. The combined efforts of the Thundertooth family, guided by their unique talents, diverted the catastrophic collision. The meteor, once destined for destruction, now harmlessly sailed past the Earth, leaving the city and its inhabitants unscathed.\n",
      "\n",
      "Source 3 of 3: |Thundertooth Part 3.docx| Source 3:\n",
      "The mayor, recognizing Thundertooth's intelligence and resourcefulness, approached him. \"Thundertooth, we need a plan to divert or neutralize the meteor. Our technology can only do so much, but with your unique abilities, perhaps we can find a solution.\"\n",
      "\n",
      "\n",
      "\n",
      "Thundertooth nodded, understanding the gravity of the situation. He gathered Lumina, Echo, Sapphire, and Ignis, explaining the urgency and the role each of them would play in the impending crisis.\n",
      "\n",
      "\n",
      "\n",
      "1. **Lumina**: Utilizing her deep understanding of technology, Lumina would enhance the city's energy systems to generate a powerful force field, providing a protective barrier against the meteor's impact.\n",
      "\n",
      "\n",
      "\n",
      "2. **Echo**: With his extraordinary mimicry abilities, Echo would amplify the emergency signals, ensuring that every citizen received timely warnings and instructions for evacuation.\n",
      "\n",
      "\n",
      "\n",
      "3. **Sapphire**: Harnessing her calming and healing powers, Sapphire would assist in calming the panicked masses, ensuring an orderly and efficient evacuation.\n",
      "\n",
      "\n",
      "\n",
      "4. **Ignis**: Drawing upon his fiery talents, Ignis would create controlled bursts of heat, attempting to alter the meteor's trajectory and reduce its destructive force.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1340.87 ms\n",
      "llama_print_timings:      sample time =     294.68 ms /   968 runs   (    0.30 ms per token,  3284.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2850.26 ms /   802 tokens (    3.55 ms per token,   281.38 tokens per second)\n",
      "llama_print_timings:        eval time =   91916.21 ms /   967 runs   (   95.05 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =   98386.46 ms\n"
     ]
    }
   ],
   "source": [
    "qa_pairs = []\n",
    "\n",
    "for indexNum, question in enumerate(TestQuestions, start=1):\n",
    "    question = question.strip() # Clean up\n",
    "\n",
    "    print(f\"\\n{indexNum}/{len(TestQuestions)}: {question}\")\n",
    "\n",
    "    response = RunQuestion(question) # Query and get  response\n",
    "\n",
    "    qa_pairs.append((question.strip(), str(response).strip())) # Add to our output array\n",
    "\n",
    "    # Displays the citations\n",
    "    for indexNumCit, node in enumerate(response.source_nodes, start=1):\n",
    "        print(f\"Source {indexNumCit} of {len(response.source_nodes)}: |{node.node.metadata['file_name']}| {node.node.get_text()}\")\n",
    "\n",
    "    # Uncomment the following line if you want to test just the first question\n",
    "    # break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Output responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 Summarise this story for me\n",
      "\n",
      "\n",
      "\n",
      "--------\n",
      "\n",
      "2/4 Who was the main protagonist?\n",
      "\n",
      "The main protagonist is Thundertooth.\n",
      "\n",
      "--------\n",
      "\n",
      "3/4 Did they have any children? If so, what were their names?\n",
      "\n",
      "[/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/\n",
      "\n",
      "--------\n",
      "\n",
      "4/4 Did anything eventful happen?\n",
      "\n",
      "[/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST\n",
      "\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for indexQA, (question, answer) in enumerate(qa_pairs, start=1):\n",
    "    print(f\"{indexQA}/{len(qa_pairs)} {question}\\n\\n{answer}\\n\\n--------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindexgeneric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
